#!/bin/sh
# -*- tcl -*- \
exec tclsh8.5 "$0" ${1+"$@"}
# ### ### ### ######### ######### #########
## (C) 2009 ActiveState Software Inc.
#
## SourceForge Pull (Extract Project information from SourceForge).
## A ForkLift application

# ### ### ### ######### ######### #########
## Usage:
##	sfpull user password project output
##
##	Extracts the information of <project> from SourceForge
##	and stores it in the directory <output>. The application
##	logs into SourceForge using the given <user/password>
##      combination, which has to be an administrator of the
##      <project>.

# ### ### ### ######### ######### #########
## NOTES ...
#
# SourceForge has three ways of authentication ...
# Really consistent. Not.
#
# (1) Project web is 'rsync over ssh' => force password, expect to
#     intercept to query, user via command line argument.
#
# (2) Mailing list archives require url get + basic authentication.
#
# (3) xml export of trackers require url + cookies, the latter we get
#     from submitting the SF login form.

# ### ### ### ######### ######### #########
## Requisites

package require Expect           ; # ssh password interaction
package require base64           ; # (Tcllib) Encoding for basic authentication.
package require fileutil         ; # (Tcllib) Helper for rsync over ssh, temp ssh config.
package require http 2.7         ; # (Core) Retrieve urls, post forms ...
package require textutil::adjust ; # (Tcllib) support for json generator code
package require tls              ; # Secure connections (https).
package require autoproxy
package require tdom

#puts [package ifneeded http [package present http]]
#proc http::Log {args} { puts HTTP:\ [join $args] }

# ### ### ### ######### ######### #########

proc main {} {
    initialize;# Required for verify_project, in the commandline.
    if {![commandline]} usage
    save_config \
	[pull_attachments [pull_tracker]] \
	[pull_mailinglists] \
	[pull_website] \
	[pull_repositories]
    return
}

proc commandline {} {
    global argv
    if {[llength $argv] != 4} { return 0 }

    global theuser        ; set theuser        [lindex $argv 0]
    global thepassword    ; set thepassword    [lindex $argv 1]
    global theproject     ; set theproject     [lindex $argv 2]
    global thedestination ; set thedestination [lindex $argv 3]

    if {$theuser        eq {}} { return 0 }
    if {$thepassword    eq {}} { return 0 }
    if {$theproject     eq {}} { return 0 }
    if {$thedestination eq {}} { return 0 }

    verify_project
    return 1
}

proc usage {} {
    global argv0
    puts stderr "Usage: $argv0 user password project outputdir"
    exit 1
}

# ### ### ### ######### ######### #########

proc initialize {} {
    #autoproxy::init localhost:8080
    http::register https 443 tls::socket
    # Fake SF into believing that an actual browser is talking to it.
    http::config -useragent {Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.13) Gecko/20101203 Firefox/3.6.13}
    return
}

proc save_config {tracker mlists website repository} {
    # tracker    = name of the tracker XML file
    # website    = name of the website directory, if any.
    # repository = name of repository directory.
    # mlists ... = lists containing the names of all project mailing
    #              lists, if any.

    global thedestination theproject thepid therepotypes theuser

    foreach {tracker attachments} $tracker break

    set tmp {}
    foreach {name archive} $mlists {
	lappend tmp $name [JsonString $archive]
    }
    set mlists $tmp

    file mkdir $thedestination
    array set config { aligned 1 indented 1 }

    if {[llength $therepotypes] == 1} {
	set repository [JsonObject \
			    type  [JsonString [lindex $therepotypes 0]] \
			    where [JsonString $repository]]
    } elseif {[llength $therepotypes]} {
	set dict {}
	foreach r $therepotypes {
	    lappend dict $r [JsonString $repository/$r]
	}	
	set repository [JsonObject \
			    types [JsonString $therepotypes] \
			    where [JsonObjectDict $dict]]
    } else {
	set repository {}
    }

    fileutil::writeFile $thedestination/Configuration \
	[JsonObject \
	     configuration-version [JsonString 1] \
	     project        [JsonString $theproject] \
	     origin         [JsonString SourceForge] \
	     origin-url     [JsonString http://sourceforge.net/projects/$theproject] \
	     origin-id      [JsonString $thepid] \
	     exporter       [JsonString $theuser] \
	     tracker        [JsonString $tracker] \
	     attachments    [JsonString $attachments] \
	     mailinglists   [JsonObjectDict $mlists] \
	     website        [JsonString $website] \
	     repository     $repository \
	     ]\n
    return
}

proc pull_tracker {} {
    global thepid
    variable attachments

    log Retrieving tracker information...

    set src https://sourceforge.net/export/xml_export2.php?group_id=$thepid
    set dst Trackers.xml

    pull-with-cookie-login $src $dst

    return $dst
}

proc pull_attachments {dst} {
    variable attachments

    # Now parse the tracker information, find all the referenced
    # attachments, and pull them as well. This code written originally
    # by Kevin Kenny (scanexport.tcl).

    log Searching for tracker attachments...
    log_barber_pole_start

    xml::parser theparser -namespace -final 1 \
	-elementstartcommand  track_startElement \
	-characterdatacommand track_charData \
	-elementendcommand    track_endElement

    set attachments {}
    set tree        {ROOT}
    theparser parsefile [dest $dst]

    log_barber_pole_done

    log Retrieving tracker attachments...

    set total [llength $attachments]
    set an 0
    set missing 0

    log_progress_start
    foreach a $attachments {
	incr an
	log_progress {} $total $an

	set ticket [dict get $a ticket]
	set base   [dict get $a url]
	set id     [dict get $a id]
	set fname  [dict get $a filename]

	set dst Attachments/file.$id

	set uri $base$ticket
##	puts -nonewline stderr "\nRetrieving $uri..."
	flush stderr
	set token [http::geturl $uri]
	if {[http::error $token] ne {}} {
	    incr missing
	    puts stderr "\nERROR RETRIEVING $uri: [http::error $token]"
	    puts stderr "Attachment $filename to $ticket will not be included"
	} else {
##	    puts stderr ok
	    file mkdir [file dirname [dest $dst]]
	    fileutil::writeFile $dst [http::data $token]
	}
	http::cleanup $token
    }

    if {$missing} {
	log_progress_done_err "$total/missing $missing"
    } else {
	log_progress_done $total
    }
    return [list $dst Attachments]
}

proc pull_mailinglists {} {
    global thepid

    log Retrieving mailing list archives...

    set token [http::geturl \
		   http://sourceforge.net/mail/?group_id=$thepid]

    #puts [http::data $token]

    set pattern "forum.php\\?forum_name=(\[^\"\]+)"
    set matches [regexp -all -inline -- $pattern [http::data $token]]
    http::cleanup $token

    set mlists {}
    foreach {dummy listname} $matches {
	lappend mlists $listname
    }

    set archives {}
    foreach listname [lsort -unique $mlists] {
	log "\t* $listname"

	set src https://lists.sourceforge.net/mbox/$listname
	set dst Mailinglists/$listname.mbox

	pull-with-basic-login $src $dst

	lappend archives $listname $dst
    }

    return $archives
}

proc pull_website {} {
    global theproject theuser thepassword thedestination

    # And a third way of doing authentication, now using SSH. We use a
    # temp config file to force ssh to use password authentication,
    # and then use Expect to intercept the pty and supply the password
    # when ssh asks for it..

    log Retrieving website...

    set config [dest SSH] ;#[fileutil::tempfile]
    fileutil::writeFile $config \
	PreferredAuthentications=password\n

    # Note that the trailing /'es added in the rsync invokation are
    # required. They ensure that the website destination directory is
    # htdocs, instead of containing a sub-directory named htdocs.
    set src ${theuser},${theproject}@web.sourceforge.net:htdocs
    set dst Website

    file mkdir $thedestination

    # No logging of the interaction.
    # Spawn rsync over ssh.
    # Wait for the password query, then supply the password, at last
    # let rsync run. We suppress the output, but drive a barber
    # pole for each line we get.

    set cmd [list exp_spawn rsync -avP -e [list ssh -F $config] $src/ [dest $dst/]]

    # An issue here may be caused by outdated SSH keys, 
    #log $cmd

    exp_log_user 0
    eval $cmd
    expect {
	"password: " {}
	"REMOTE HOST IDENTIFICATION HAS CHANGED" {
	    log {Please fix your known_hosts file}
	    log {Remove the entry for web.sourceforge.net}
	    exit
	}
	"Are you sure you want to continue connecting" {
	    log {We are sure...}
	    exp_send yes\r
	}
    }
    log {Sending password...}
    exp_send  $thepassword\r
    log_barber_pole_start
    expect {
	"*\r" {
	    log_barber_pole
	    exp_continue
	}
	eof {}
    }
    log_barber_pole_done

    # Get rid of the temp configuration.
    file delete $config
    return $dst
}

proc pull_repositories {} {
    global therepotypes

    set dst Repository

    if {[llength $therepotypes] == 1} {
	pull_repository [lindex $therepotypes 0] $dst
    } else {
	foreach t $therepotypes {
	    pull_repository $t $dst/$t
	}
    }

    return $dst
}

proc pull_repository {type dst} {
    global theproject thedestination

    log Retrieving project $type repository...

    # Note: This is the only part of the project where no
    # authentication is required. I.e. this is something anybody can
    # do, for any project.

    if {$type eq "svn"} {
	set root $type
    } else {
	# cvs, hg, git, bzr
	set root ${type}root
    }

    set src ${theproject}.${type}.sourceforge.net::$root/$theproject/*

    file mkdir [file dirname $thedestination/$dst]

    log_barber_pole_start
    exp_log_user 0
    exp_spawn rsync -avP $src $thedestination/$dst
    expect {
	"*\r" {
	    log_barber_pole
	    exp_continue
	}
	eof {}
    }
    log_barber_pole_done
    return $dst
}

# ### ### ### ######### ######### #########
## This code originally written by Kevin Kenny (scanexport.tcl). Here
## in sfpull it has been reduced to get only the data needed to
## retrieve all ticket attachments.

# startElement --
#
#	Callback executed at the start of any XML element in the
#	SourceForge export
#
# Parameters:
#	name - Element name
#	attlist - List of attributes attached to the element.

proc track_startElement {name attlist} {
    variable curAttachmentFields
    variable tree
    variable chardata

    set chardata {}
    lappend tree $name

    log_barber_pole

    contextmatch {
	{tracker_item attachments attachment} {
	    # Start of an attachment - clear the fields
	    set curAttachmentFields {}
	}
    }
}

# charData --
#
#	Callback for character data in the XML
#
# Parameters:
#	data - Data to include in the enclosing element.
#
# Results:
#	None.

proc track_charData {data} {
    variable chardata
    append chardata $data
}

# endElement --
#
#	Callback for the end of an element
#
# Parameters:
#	name - Name of the element being ended.
#
# Results:
#	None.

proc track_endElement {name} {

    variable tree
    variable chardata
    variable curAttachmentFields
    variable attachments
    variable curTicket

    contextmatch {
	{tracker_item id} {
	    # Ticket ID - stash for use in attachments.
	    set curTicket $chardata
	}
	{tracker_item attachments attachment url} {
	    # URL (incorrect, but fixable) of an attachment
	    dict set curAttachmentFields url $chardata
	}
	{tracker_item attachments attachment id} {
	    # Integer ID of an attachment
	    dict set curAttachmentFields id $chardata
	}
	{tracker_item attachments attachment filename} {
	    # File name of an attachment
	    dict set curAttachmentFields filename $chardata
	}
	{tracker_item attachments attachment description} {
	    # Human readable description of an attachment
	    dict set curAttachmentFields description $chardata
	}
	{tracker_item attachments attachment filesize} {
	    # File size of an attachment
	    dict set curAttachmentFields filesize $chardata
	}
	{tracker_item attachments attachment filetype} {
	    # File type of an attachment
	    dict set curAttachmentFields filetype $chardata
	}
	{tracker_item attachments attachment date} {
	    # Date (seconds from Unix epoch) of an attachment
	    dict set curAttachmentFields date $chardata
	}
	{tracker_item attachments attachment submitter} {
	    # User that submitted an attachment
	    dict set curAttachmentFields submitter $chardata
	}
	{tracker_item attachments attachment} {
	    # End of an attachment
	    dict set curAttachmentFields ticket $curTicket
	    lappend attachments $curAttachmentFields
	}
	{document} {
#	    puts "Trackers: $trackers"
	}
    }
    set tree [lrange $tree 0 end-1]
}

# contextmatch --
#
#	Match on the context in the XML parse
#
# Parameters:
#	what - Dictionary whose keys are contexts and whose values
#	       are scripts. Each context is a list of element tags;
#	       the context must match the righmost part of the path
#	       to the current element.
#
# Side effects:
#	Whatever the matching scripts do.

proc contextmatch {what} {
    variable tree
    set l [expr {[llength $tree] - 1}]
    foreach {pattern script} $what {
	set i [expr {[llength $pattern] - 1}]
	if {$i <= $l} {
	    set ok 1
	    for {set j $l} {$ok && $i >= 0} {incr i -1; incr j -1} {
		if {[lindex $pattern $i] ne [lindex $tree $j]} {
		    set ok 0
		}
	    }
	    if {$ok} {
		uplevel 1 $script
	    }
	}
    }
}

# ### ### ### ######### ######### #########

proc verify_project {} {
    global theproject thepid therepotypes

    set url http://sourceforge.net/projects/$theproject/

    puts "Get project id of $url..."

    set token [http::geturl $url]
    set data  [http::data $token]
    http::cleanup $token

    if {[regexp {Invalid Project} $data]} {
	log "Project $theproject = INVALID"
	log "I.e. sourceForge claims that it doesn't know this name."
	log "Please check your spelling."
	exit
    }

    #puts <$data>

    set pattern "group_id=(\[0-9\]+)"
    if {![regexp $pattern $data -> thepid]} {
	log "Project $theproject : Unable to determine pid"
	puts $data
	return -code error FAIL/id
    }

    puts "Get repository type of project $thepid..."

    # Supported repository types: cvs, svn, hg, git, bzr.

    # In the main page the repository type is hidden somewhere within
    # a javascript which is loaded later. The public_info page however
    # still seems to provide us with this information directly in the
    # HTML. It is however a page requiring login.

    set url  https://sourceforge.net/project/admin/public_info.php?group_id=$thepid
    set tmp  [pull-with-cookie-login $url public_info.html]
    set data [fileutil::cat $tmp]

    set pattern "scm/\\?type=(\[^&\]+)"
    set therepotypes {}
    foreach line [split $data \n] {
	if {![regexp $pattern $line -> repotype]} continue
	if {[regexp disabled $line]} continue
	lappend therepotypes $repotype
    }

    if {![llength $therepotypes]} {
	log "Project $theproject = $thepid (WARNING No repositories found)"
	#return -code error FAIL/type
    }

    log "Project $theproject = $thepid ($therepotypes)"
    return
}

proc pull-with-cookie-login {url file} {
    global thedestination

    variable thecookies

    set dst  $thedestination/$file
    set tmp  [fileutil::tempfile]

    # The login credentials are transmitted indirectly, through us
    # having the cookie returned by the login form we submitted (see
    # the procedure mauve::login where this is done).

    # Using protocol 1.0 disables chunked transfer, something SF will
    # do for 1.1, and which http doesn't handle properly for -channel.

    log_progress_start

    set chan  [open $tmp w]
    set token [http::geturl $url \
		   -protocol 1.0 \
		   -channel $chan \
		   -headers [login_cookies] \
		   -progress log_progress]
    log_progress_done [file size $tmp]

    http::wait    $token
    http::cleanup $token
    close $chan

    file mkdir [file dirname $dst]
    #file copy -force $tmp $dst
    file rename -force $tmp $dst

    return $dst
}

proc pull-with-basic-login {url file} {
    global thedestination theuser thepassword

    set dst $thedestination/$file
    set tmp [fileutil::tempfile]

    # Here the login credentials are transmitted through 'Basic' http
    # authentication.

    # Using protocol 1.0 disables chunked transfer, something SF will
    # do for 1.1, and which http doesn't handle properly for -channel.

    log_progress_start

    set chan [open $tmp w]
    fconfigure $chan -encoding binary -translation binary

    # The transfer is configured binary to avoid problems if a mail
    # contains a bogus encoding (spam), tripping the core (invalid
    # argument during a write, improper character, 7MB into a 48 MB
    # file. tcl-core mail archive triggered this).

    #log Using $theuser:$thepassword
    #log Using [list Authorization [concat "Basic" [base64::encode $theuser:$thepassword]]]

    set token [http::geturl $url \
		   -binary 1 \
		   -protocol 1.0 \
		   -channel $chan \
		   -headers [list Authorization \
				 [concat "Basic" \
				      [base64::encode $theuser:$thepassword]]] \
		   -progress log_progress]
    log_progress_done [file size $tmp]

    http::wait    $token
    http::cleanup $token
    close $chan

    file mkdir [file dirname $dst]
    file rename -force $tmp $dst
    return
}

# ### ### ### ######### ######### #########

proc login_cookies {} {
    global thecookies
    if {[info exists thecookies] && [llength $thecookies]} {
	puts {Cached cookies...}
	return $thecookies
    }

    global theproject theuser thepassword

    # Run the sourceforge authentication form.
    set url https://sourceforge.net/account/login.php

    # form_loginname = user
    # form_pw        = password
    # login          = The submit button.

    set query [http::formatQuery \
			       form_loginname $theuser \
			       form_pw        $thepassword \
			       login          {Log in}]

    #puts Q($query)

    set token [http::geturl $url \
		   -query $query]
    #set meta [http::meta $token]

    #puts RESPONSE_____________________________________________
    #parray $token
    #puts _____________________________________________________

    set meta [set ${token}(meta)]
    http::cleanup $token

    set lines {}
    foreach {k v} $meta {
	if {$k ne "Set-Cookie"} continue
	set cookie [lindex [split $v {;}] 0]
	# Cookie is in the form of 'k=v'.
	# We can use this form directly.
	lappend lines $cookie
    }
    lappend lines SFUSER=1

    set thecookies [list Cookie: [join $lines {;}]]

    log Logged in as $theuser
    #log $thecookies
    return $thecookies
}

# ### ### ### ######### ######### #########
## Helper. Interface to log output and progress bars.

proc log {args} {
    puts [join $args]
    return
}

proc log_barber_pole_start {} {
    global thepole
    set    thepole {*   *   *   }
    return
}

proc log_barber_pole {} {
    global thepole
    puts -nonewline \r$thepole
    flush stdout
    set thepole [string range $thepole 1 end][string index $thepole 0]
    return
}

proc log_barber_pole_done {} {
    puts "\rOK                                           "
    return
}

proc log_progress_start {} {}

proc log_progress {token total current} {
    if {$total == 0} { set total ??? }

    puts -nonewline \r$current/$total
    flush stdout
    return
}

proc log_progress_done {msg} {
    puts "\rOK $msg                                     "
    return
}

proc log_progress_done_err {msg} {
    puts "\rERR $msg                                     "
    return
}

proc dest {path} {
    global thedestination
    file mkdir $thedestination
    return [file join $thedestination $path]
}

# ### ### ### ######### ######### #########
## Helper code to generate JSON structures.
## Snarfed from Tcllib, the json export plugins for
## doctools2{idx,toc},
##
## Expects an array variable 'config' in the caller, containing the
## keys 'aligned' and 'indented' (Bboth mapping to a boolean value).

proc JsonQuotes {} {
    return [list "\"" "\\\"" / \\/ \\ \\\\ \b \\b \f \\f \n \\n \r \\r \t \\t]
}

proc JsonString {s} {
    return "\"[string map [JsonQuotes] $s]\""
}

proc JsonArray {args} {
    upvar 1 config config
    return [JsonArrayList $args]
}

proc JsonArrayList {list} {
    # compact form.
    return "\[[join $list ,]\]"
}

proc JsonObject {args} {
    upvar 1 config config
    return [JsonObjectDict $args]
}

proc JsonObjectDict {dict} {
    # The dict maps string keys to json-formatted data. I.e. we have
    # to quote the keys, but not the values, as the latter are already
    # in the proper format.
    upvar 1 config config

    set tmp {}
    foreach {k v} $dict { lappend tmp [JsonString $k] $v }
    set dict $tmp

    if {$config(aligned)} { Align $dict max }

    if {$config(indented)} {
	set content {}
	foreach {k v} $dict {
	    if {$config(aligned)} { set k [FmtR max $k] }
	    if {[string match *\n* $v]} {
		# multi-line value
		lappend content "    $k : [textutil::adjust::indent $v {    } 1]"
	    } else {
		# single line value.
		lappend content "    $k : $v"
	    }
	}
	if {[llength $content]} {
	    return "\{\n[join $content ,\n]\n\}"
	} else {
	    return "\{\}"
	}
    } else {
	# ultra compact form.
	set tmp {}
	foreach {k v} $dict { lappend tmp "$k:$v" }
	return "\{[join $tmp ,]\}"
    }
}

proc Align {dict mv} {
    upvar 1 $mv max
    # Generate a list of references sortable by name, and also find the
    # max length of all relevant names.
    set max 0
    foreach {str _} $dict { Max max $str }
    return
}

proc Max {v str} {
    upvar 1 $v max
    set x [string length $str]
    if {$x <= $max} return
    set max $x
    return
}

proc FmtR {v str} {
    upvar 1 $v max
    return $str[string repeat { } [expr {$max - [string length $str]}]]
}

# ### ### ### ######### ######### #########

main
exit
